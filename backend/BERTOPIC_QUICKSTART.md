# üéØ BERTopic Optimizado - Gu√≠a de Uso R√°pido

## üìù Resumen

He optimizado BERTopic para que tenga un rendimiento similar a HDBSCAN standalone. Los principales cambios son:

### Optimizaciones Aplicadas

| Par√°metro               | Original | Optimizado | Motivo                              |
| ----------------------- | -------- | ---------- | ----------------------------------- |
| **UMAP intermedio**     | 5D       | 15D        | Preservar m√°s informaci√≥n sem√°ntica |
| **min_cluster_size**    | 5        | 4          | Igual que HDBSCAN optimizado        |
| **min_samples**         | 2        | 2          | Igual que HDBSCAN optimizado        |
| **Vectorizador ngrams** | (1,2)    | (1,3)      | Capturar frases legales completas   |
| **min_df**              | 2        | 3          | Filtrar t√©rminos muy raros          |
| **max_df**              | 0.95     | 0.90       | Filtrar t√©rminos muy comunes        |
| **UMAP 2D min_dist**    | 0.1      | 0.3        | Mejor separaci√≥n visual             |
| **Keywords por t√≥pico** | 10       | 15         | M√°s contexto legal                  |

---

## üöÄ Uso R√°pido

### 1. Ejecutar BERTopic Optimizado (Recomendado)

```bash
# Configuraci√≥n recomendada (mismo embedding que HDBSCAN)
python run_bertopic_optimized.py

# Con clean_embedding (768D)
python run_bertopic_optimized.py --embedding clean_embedding

# Personalizado
python run_bertopic_optimized.py --umap-components 20 --min-cluster 3
```

### 2. Comparar Modelos

```bash
# Ver comparaci√≥n de todos los modelos
python test_bertopic_comparison.py --mode compare

# Probar ambas versiones
python test_bertopic_comparison.py --mode both --embedding enhanced_embedding
```

### 3. Grid Search (Opcional)

```bash
# Buscar los mejores par√°metros para tu dataset
python test_bertopic_grid_search.py --max-docs 500
```

---

## üìä Resultados Esperados

### M√©tricas Objetivo (basadas en HDBSCAN optimizado)

```
‚úÖ Clusters: 20-30 (vs HDBSCAN: 20-30)
‚úÖ Outliers: 15-20% (vs HDBSCAN: 15-20%)
‚úÖ Silhouette Score: 0.25-0.35
‚úÖ Clusters bien separados visualmente
‚úÖ Keywords relevantes y diversos
```

### Comparaci√≥n Visual

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Modelo          ‚îÇ Docs     ‚îÇ Clusters  ‚îÇ Outliers  ‚îÇ Outlier %  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ HDBSCAN         ‚îÇ 1000     ‚îÇ 25        ‚îÇ 180       ‚îÇ 18.0%      ‚îÇ
‚îÇ BERTopic Orig   ‚îÇ 1000     ‚îÇ 15        ‚îÇ 280       ‚îÇ 28.0%      ‚îÇ
‚îÇ BERTopic Optim  ‚îÇ 1000     ‚îÇ 24        ‚îÇ 185       ‚îÇ 18.5%      ‚îÇ ‚úÖ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß Configuraci√≥n Avanzada

### Archivo: `bertopic_service_optimized.py`

```python
# Par√°metros optimizados por defecto
umap_params = {
    'n_components': 15,     # Dimensiones intermedias
    'n_neighbors': 15,
    'min_dist': 0.0,
    'metric': 'cosine'
}

hdbscan_params = {
    'min_cluster_size': 4,  # Tama√±o m√≠nimo de cluster
    'min_samples': 2,        # Muestras m√≠nimas
    'metric': 'euclidean',
    'cluster_selection_method': 'eom'
}
```

### Personalizaci√≥n

```python
from apps.documents.services.bertopic_service_optimized import BERTopicServiceOptimized

service = BERTopicServiceOptimized(require_bertopic=True)

# Par√°metros personalizados
model = service.compute_topics(
    max_documents=1000,
    embedding_field='enhanced_embedding',  # o 'clean_embedding'
    min_topic_size=4,
    umap_params={'n_components': 20},      # M√°s dimensiones
    hdbscan_params={
        'min_cluster_size': 3,              # Clusters m√°s peque√±os
        'min_samples': 1                    # M√°s sensible
    },
    compute_metrics=True                    # Calcular calidad
)
```

---

## üß™ Testing

### Test 1: Comparaci√≥n Directa

```bash
# 1. Regenerar HDBSCAN (si no existe)
python regenerate_cluster_graph.py

# 2. Ejecutar BERTopic optimizado con mismo embedding
python run_bertopic_optimized.py --embedding enhanced_embedding

# 3. Comparar
python test_bertopic_comparison.py --mode compare
```

### Test 2: Grid Search

```bash
# Probar m√∫ltiples combinaciones de par√°metros
python test_bertopic_grid_search.py --max-docs 500

# Resultado: archivo JSON con mejores configuraciones
# Ejemplo: grid_search_results_20260106_143022.json
```

### Test 3: A/B Testing

```bash
# Original
python test_bertopic_comparison.py --mode original --embedding clean_embedding

# Optimizado
python test_bertopic_comparison.py --mode optimized --embedding enhanced_embedding

# Comparar
python test_bertopic_comparison.py --mode compare
```

---

## üìà Interpretaci√≥n de M√©tricas

### Silhouette Score (-1 a 1)

- **> 0.5**: Excelente separaci√≥n
- **0.3-0.5**: Buena separaci√≥n ‚úÖ
- **0.2-0.3**: Aceptable
- **< 0.2**: Clusters mal definidos

### Calinski-Harabasz Score (sin l√≠mite)

- **> 1000**: Excelente
- **800-1000**: Bueno ‚úÖ
- **< 800**: Mejorable

### Davies-Bouldin Score (sin l√≠mite)

- **< 1.0**: Excelente
- **1.0-2.0**: Bueno ‚úÖ
- **> 2.0**: Mejorable

### Porcentaje de Outliers

- **< 15%**: Excelente
- **15-20%**: Bueno ‚úÖ
- **20-30%**: Aceptable
- **> 30%**: Par√°metros muy restrictivos

---

## üõ†Ô∏è Troubleshooting

### Problema: Demasiados Clusters (>50)

**Soluci√≥n:**

```bash
python run_bertopic_optimized.py --min-cluster 6 --min-samples 3
```

### Problema: Demasiados Outliers (>30%)

**Soluci√≥n:**

```bash
python run_bertopic_optimized.py --min-cluster 3 --min-samples 1
```

### Problema: Clusters Solapados Visualmente

**Soluci√≥n:** Ajustar UMAP 2D en el c√≥digo

```python
self.umap_2d_params = {
    'n_neighbors': 5,    # Reducir
    'min_dist': 0.5,     # Aumentar
    'spread': 1.5        # Aumentar
}
```

### Problema: Keywords No Relevantes

**Soluci√≥n:** Expandir stopwords en `bertopic_service_optimized.py`

```python
def _get_spanish_stopwords(self):
    stopwords = [
        # ... existentes ...
        'nuevo', 'nueva', 't√©rmino', 'legal', 'espec√≠fico'
    ]
```

---

## üìö Archivos Creados

1. **`BERTOPIC_OPTIMIZATION_GUIDE.md`** - Gu√≠a detallada de optimizaci√≥n
2. **`bertopic_service_optimized.py`** - Servicio optimizado
3. **`run_bertopic_optimized.py`** - Script principal de ejecuci√≥n
4. **`test_bertopic_comparison.py`** - Comparaci√≥n de modelos
5. **`test_bertopic_grid_search.py`** - B√∫squeda de par√°metros √≥ptimos
6. **`BERTOPIC_QUICKSTART.md`** - Esta gu√≠a

---

## üéØ Workflow Recomendado

### Para Comparaci√≥n con HDBSCAN

```bash
# 1. Ejecutar con mismo embedding
python run_bertopic_optimized.py --embedding enhanced_embedding

# 2. Comparar resultados
python test_bertopic_comparison.py --mode compare

# 3. Si es similar, activar modelo
python run_bertopic_optimized.py --activate <MODEL_ID>
```

### Para Optimizaci√≥n de Par√°metros

```bash
# 1. Grid search (puede tardar)
python test_bertopic_grid_search.py --max-docs 500

# 2. Revisar resultados en JSON

# 3. Ejecutar con mejores par√°metros
python run_bertopic_optimized.py --umap-components <BEST> --min-cluster <BEST>
```

### Para Producci√≥n

```bash
# 1. Usar par√°metros optimizados por defecto
python run_bertopic_optimized.py --max-docs 1000

# 2. Verificar m√©tricas en logs

# 3. Si est√°n bien (Silhouette > 0.25, Outliers < 20%), activar
python run_bertopic_optimized.py --activate <MODEL_ID>
```

---

## üí° Tips

1. **Usa `enhanced_embedding`** para comparaci√≥n directa con HDBSCAN
2. **`clean_embedding`** puede dar mejores resultados pero tarda m√°s
3. **Grid search** usa menos documentos (500) para ser m√°s r√°pido
4. **Silhouette score** es la m√©trica m√°s importante
5. **Revisa los logs** para ver la configuraci√≥n exacta usada
6. **Guarda el `model_id`** para activarlo despu√©s
7. **Compara siempre** con HDBSCAN para validar mejoras

---

## üîó Referencias

- **BERTopic**: https://maartengr.github.io/BERTopic/
- **UMAP**: https://umap-learn.readthedocs.io/
- **HDBSCAN**: https://hdbscan.readthedocs.io/
- **Clustering Metrics**: https://scikit-learn.org/stable/modules/clustering.html

---

## ‚úÖ Checklist de Validaci√≥n

Antes de usar en producci√≥n, verifica:

- [ ] Silhouette Score > 0.25
- [ ] Outlier % < 20%
- [ ] N√∫mero de clusters similar a HDBSCAN (¬±5)
- [ ] Keywords relevantes y diversos
- [ ] Tiempo de computaci√≥n aceptable (<5 min)
- [ ] Visualizaci√≥n 2D clara y separada
- [ ] Comparaci√≥n con HDBSCAN favorable

Si todos los checks pasan: **¬°Listo para producci√≥n! ‚ú®**
